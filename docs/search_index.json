[["index.html", "Ecogeographic Variation 1 Getting started and Learning R", " Ecogeographic Variation 1 Getting started and Learning R If you have not used R previously, we recommend that you work through Chapters 1 to 10 of the Quantitative training guide, which includes instructions on how to install R on a computer and the basics on coding in R. In particular, in this lab you will work with the commands for Handling data using R and Making graphs in R. You will also learn how to perform statistical analyses in R. "],["how-to-examine-and-analyze-the-data-in-r.html", "2 How to examine and analyze the data in R 2.1 Data importation and examination", " 2 How to examine and analyze the data in R 2.1 Data importation and examination To learn more about the codes being used in this section, we recommend you read through Chapters 8 and 9 of the Quantitative training guide where each line of code has been clearly explained. Begin by making a folder on your D: drive (if you are working in a university computer lab), or on your Desktop (if you are working on your own computer), where you will work on this assignment. Download the data from D2L and save it as a .csv file to the folder you made on the D: drive (or your Desktop). You may rename the .csv file you downloaded as coyote.csv. Open R Studio and save a new R Script. In the top menu select File &gt; New File &gt; R Script, then File &gt; Save As. Save the .R (the R Script) to the folder you made on your D: drive (or Desktop). It is very important to save both of these files in the same folder. Now you can load your data by running the following command: coyote &lt;- read.csv(file = &quot;coyote.csv&quot;) The above command is essential to your analysis so you should add it to your R Script. Your R Script should look something like this: The values in your dataset might look different from what I have in this dataset. Note that this is just a sample data to guide you through the analysis. You can explore the data using the following commands. This is an important practice to ensure that your data is loaded. head(coyote) ## Record_no Student State_Province Region Spec_no Year SL_mm ## 1 1 Chelsea Alabama SE 16021103 before_2015 190.1322 ## 2 2 Chelsea Alaska AK 12091204 2012 182.2411 ## 3 3 Chelsea Alaska AK 12091205 2012 192.7866 ## 4 4 Chelsea Alaska AK 12091206 2012 197.3735 ## 5 5 Chelsea Alaska AK 12091207 2012 202.3060 ## 6 6 Chelsea Alaska AK 131029001 2013 161.0606 ## BB_mm ## 1 56.25876 ## 2 55.75611 ## 3 61.46209 ## 4 58.66213 ## 5 61.02975 ## 6 45.21615 str(coyote) ## &#39;data.frame&#39;: 120 obs. of 8 variables: ## $ Record_no : int 1 2 3 4 5 6 7 8 9 10 ... ## $ Student : chr &quot;Chelsea&quot; &quot;Chelsea&quot; &quot;Chelsea&quot; &quot;Chelsea&quot; ... ## $ State_Province: chr &quot;Alabama&quot; &quot;Alaska&quot; &quot;Alaska&quot; &quot;Alaska&quot; ... ## $ Region : chr &quot;SE&quot; &quot;AK&quot; &quot;AK&quot; &quot;AK&quot; ... ## $ Spec_no : num 16021103 12091204 12091205 12091206 12091207 ... ## $ Year : chr &quot;before_2015&quot; &quot;2012&quot; &quot;2012&quot; &quot;2012&quot; ... ## $ SL_mm : num 190 182 193 197 202 ... ## $ BB_mm : num 56.3 55.8 61.5 58.7 61 ... To list the names of the columns of the data: names(coyote) ## [1] &quot;Record_no&quot; &quot;Student&quot; &quot;State_Province&quot; &quot;Region&quot; ## [5] &quot;Spec_no&quot; &quot;Year&quot; &quot;SL_mm&quot; &quot;BB_mm&quot; Note that the commands to explore the data are good to run in the Console because we want to have a general knowledge of how the data looks like: These commands act as query rather than an essential part of the analysis. If your data has not loaded, the most likely problem is a spelling error or problems with specifying the path to coyote.csv. You might try: the RStudio way of importing your data, or moving coyote.csv to your working directory. To find out your working directory type getwd() into your Console: getwd() ## [1] &quot;/Users/jbaafi/Desktop/Ecog-variation&quot; For more help on resolving problems with loading data and setting your working directory you can read through section 2.1 of this study guide. "],["making-graphs.html", "3 Making graphs", " 3 Making graphs Before we can make the graphs we will need to install and load the necessary packages. First, we would have to install the package ggplot2. To do this, we will run the following code install.packages(&quot;ggplot2&quot;) Now we load the installed package into R by running the code library(ggplot2) Now that the required package has been installed and loaded, we are going to create the frequency distribution of each variable. The distribution for SL_mm is produced by running the following code: ggplot(coyote, aes(x=SL_mm)) + geom_histogram() + theme_classic() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. We can also create the frequency distribution for BB_mm by running the following code: ggplot(coyote, aes(x=BB_mm)) + geom_histogram() + theme_classic() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## Warning: Removed 1 rows containing non-finite values (stat_bin). These lines of code are very important to the analysis so you would want to add them as the next lines of code in your R Script. At this stage your R script will look like this: Now we create a scatter plot of the two variables (SL_mm and BB_mm) using the following code. ggplot(coyote, aes(x = SL_mm, y = BB_mm)) + geom_point(size = 2) + theme_classic() + xlab(&quot;Skull length&quot;) + ylab(&quot;Braincase breadth&quot;) ## Warning: Removed 1 rows containing missing values (geom_point). On this scatter plot, we show the relationship between the SL_mm and BB_mm by treating BB_mm as a function of SL_mm. If you have outliers in your data and you wish to remove them you can do so using the following code. Replace spec no. of the outlier of your data in the code with the actual spec number of your data. coyote &lt;- coyote %&gt;% filter(Spec_no != &quot;spec no. of the outlier of your data&quot;) "],["making-tables.html", "4 Making tables", " 4 Making tables Before we make the tables we will need to install and load the necessary packages. The package needed to manipulate data and create dataframe is the dplyr package. To help us compute the descriptive statistics of the data, we will need to install the dplyr package. The following code will help you to install this package. You may skip this step if you have already installed the package. install.packages(&quot;dplyr&quot;) After successful installation, we will have to load it into R using the code library(dplyr) Now we are good to manipulate the data and create data frames. The first dataframe gives a descriptive statistics (summary) of the skull length (SL_mm) by region. coyoteSL &lt;- coyote %&gt;% filter(!is.na(coyote$SL_mm)) as.data.frame(summarize(group_by(coyoteSL, Region), SL_mean = mean(SL_mm), SL_SD = sd(SL_mm), n = n())) ## Region SL_mean SL_SD n ## 1 AK 185.1677 14.247055 18 ## 2 CTR 193.8521 10.399843 21 ## 3 NE 200.3899 11.728498 21 ## 4 NW 184.3920 7.916187 18 ## 5 SE 200.3848 14.499354 2 ## 6 SW 187.6740 8.427188 40 The overall mean and standard deviation of the skull length and the number of skulls can be found by running this code: as.data.frame(summarize(group_by(coyoteSL), SL_mean = mean(SL_mm), SL_SD = sd(SL_mm), n = n())) ## SL_mean SL_SD n ## 1 190.324 11.73755 120 We can also create a dataframe that gives a summary of the braincase breadth (BB_mm) by region. This is done by running the code: coyoteBB &lt;- coyote %&gt;% filter(!is.na(coyote$BB_mm)) as.data.frame(summarize(group_by(coyoteBB, Region), BB_mean = mean(BB_mm), BB_SD = sd(BB_mm), n = n())) ## Region BB_mean BB_SD n ## 1 AK 56.20690 3.940768 18 ## 2 CTR 57.27160 2.352801 21 ## 3 NE 59.45019 2.398987 21 ## 4 NW 56.95291 2.635666 18 ## 5 SE 58.47589 3.135494 2 ## 6 SW 56.53313 2.252482 39 The overall mean and standard deviation of the braincase breadth (BB_mm) and the number of skulls measured can be found by running this code: as.data.frame(summarize(group_by(coyoteBB), BB_mean = mean(BB_mm), BB_SD = sd(BB_mm), n = n())) ## BB_mean BB_SD n ## 1 57.22502 2.846884 119 "],["geographic-variation-in-coyote-skulls.html", "5 Geographic variation in coyote skulls 5.1 Analysis of variance (ANOVA)", " 5 Geographic variation in coyote skulls There are many ways to test for geographic differences statistically. In this lab, we will test for differences between AK and the rest of the samples; NW and NE; and NW and SW. First we will visualize the data in separate boxplots for each variable, with one box for each of the five regions. We create the boxplots using the ggplot() function. If you have not used ggplot previously, we recommend that you work through a guide on how to make plots with ggplot. The following code creates a boxplot with skull length as a function of region (in other words, the boxplot shows the skull length for each region). ggplot(coyote, aes(x = Region, y = SL_mm)) + geom_boxplot()+ theme_classic() + ylab(&quot;Skull length&quot;) We also create a boxplot with braincase breadth as a function of region (the boxplot shows the braincase breadth for each region). ggplot(coyote, aes(x = Region, y =BB_mm)) + geom_boxplot()+ theme_classic() + ylab(&quot;Braincase breadth&quot;) ## Warning: Removed 1 rows containing non-finite values (stat_boxplot). 5.1 Analysis of variance (ANOVA) Analysis of Variance (ANOVA) is a statistical test to determine whether two or more population means are different. There are several versions of the ANOVA e.g., one-way ANOVA, two-way ANOVA, etc. In this section, we conduct one-way ANOVA on the comparisons for both variables (that is the skull length and the braincase breadth) and summarize the results in tables. We first do the comparison for the SL_mm variable. We add a a variable GroupsAKRest to the data where all other regions apart from AK is taken as others. coyoteA &lt;- mutate(coyote, GroupsAKRest = ifelse(Region == &quot;AK&quot;, &quot;AK&quot;, &quot;Others&quot;)) coyoteA Now we define a model with SL_mm as a function of GroupsAKRest. modelSL&lt;- lm(SL_mm~GroupsAKRest, data = coyoteA) Now to get the details of the model described in the previous line, we will have to use the summary() function summary(modelSL) ## ## Call: ## lm(formula = SL_mm ~ GroupsAKRest, data = coyoteA) ## ## Residuals: ## Min 1Q Median 3Q Max ## -28.9123 -7.6644 -0.7236 6.6149 28.5031 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 185.168 2.730 67.823 &lt;2e-16 *** ## GroupsAKRestOthers 6.066 2.961 2.049 0.0427 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 11.58 on 118 degrees of freedom ## Multiple R-squared: 0.03434, Adjusted R-squared: 0.02616 ## F-statistic: 4.197 on 1 and 118 DF, p-value: 0.04273 At this point we can do the analysis of variance for AK and the rest of the regions. The ANOVA table can be found by running the code: anova(modelSL) ## Analysis of Variance Table ## ## Response: SL_mm ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## GroupsAKRest 1 563 563.03 4.1965 0.04273 * ## Residuals 118 15832 134.17 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We can replace SL_mm by BB_mm to do a similar comparison in the braincase breadth for AK and the other regions. Let me call this modelBB. modelBB &lt;- lm(BB_mm~GroupsAKRest, data = coyoteA ) To get details of modelBB we use the summary() function summary(modelBB) ## ## Call: ## lm(formula = BB_mm ~ GroupsAKRest, data = coyoteA) ## ## Residuals: ## Min 1Q Median 3Q Max ## -10.9907 -1.1744 -0.1647 1.9002 7.8721 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 56.2069 0.6661 84.384 &lt;2e-16 *** ## GroupsAKRestOthers 1.1996 0.7230 1.659 0.0998 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.826 on 117 degrees of freedom ## (1 observation deleted due to missingness) ## Multiple R-squared: 0.02299, Adjusted R-squared: 0.01464 ## F-statistic: 2.753 on 1 and 117 DF, p-value: 0.09977 The ANOVA table can be found by running the code: anova(modelBB) ## Analysis of Variance Table ## ## Response: BB_mm ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## GroupsAKRest 1 21.98 21.9837 2.7527 0.09977 . ## Residuals 117 934.38 7.9861 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We also conduct the ANOVA for NW and NE in a similar manner as was done above. We would have to filter the coyote data using the filter() function in the dplyr package to select the NW and NE regions. We will save this data as coyoteNW_NE. coyoteNW_NE &lt;- coyote %&gt;% filter(Region == &quot;NW&quot; | Region == &quot;NE&quot;) Now we define a model SL_mm as a function of the two regions NW and NE. Let us call this modelSL1 to different it from the previous model. modelSL1 &lt;- lm(SL_mm~Region, data = coyoteNW_NE) summary(modelSL1) ## ## Call: ## lm(formula = SL_mm ~ Region, data = coyoteNW_NE) ## ## Residuals: ## Min 1Q Median 3Q Max ## -18.3207 -5.7213 -0.8156 8.3874 19.3472 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 200.390 2.216 90.418 &lt; 2e-16 *** ## RegionNW -15.998 3.262 -4.904 1.9e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 10.16 on 37 degrees of freedom ## Multiple R-squared: 0.3939, Adjusted R-squared: 0.3775 ## F-statistic: 24.05 on 1 and 37 DF, p-value: 1.897e-05 The Anova table for modelSL1 can also be obtained: anova(modelSL1) ## Analysis of Variance Table ## ## Response: SL_mm ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Region 1 2480.6 2480.58 24.049 1.897e-05 *** ## Residuals 37 3816.5 103.15 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We do a similar model for BB_mm with the two regions NW and NE. Let us call this modelBB1 to different it from the previous model. modelBB1&lt;- lm(BB_mm~Region, data = coyoteNW_NE ) summary(modelBB1) ## ## Call: ## lm(formula = BB_mm ~ Region, data = coyoteNW_NE) ## ## Residuals: ## Min 1Q Median 3Q Max ## -6.6929 -1.8178 0.2335 1.3519 5.8284 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 59.4502 0.5478 108.518 &lt; 2e-16 *** ## RegionNW -2.4973 0.8064 -3.097 0.00372 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.511 on 37 degrees of freedom ## Multiple R-squared: 0.2058, Adjusted R-squared: 0.1844 ## F-statistic: 9.59 on 1 and 37 DF, p-value: 0.003721 The Anova table for modelBB1 can also be obtained by the code: anova(modelBB1) ## Analysis of Variance Table ## ## Response: BB_mm ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Region 1 60.445 60.445 9.5904 0.003721 ** ## Residuals 37 233.197 6.303 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 11.Now we want to do the comparison for NW and SW. We would have to filter the data using the filter() function in dplyr to select the NW and SW regions. Let us save this data as coyoteNW_SW. coyoteNW_SW &lt;- coyote %&gt;% filter(Region == &quot;NW&quot; | Region == &quot;SW&quot;) We define a model for SL_mm with the regions being NW and SW. Let us call this model modelSL2. modelSL2 &lt;- lm(SL_mm ~Region, data = coyoteNW_SW ) summary(modelSL2) ## ## Call: ## lm(formula = SL_mm ~ Region, data = coyoteNW_SW) ## ## Residuals: ## Min 1Q Median 3Q Max ## -18.5229 -4.6935 0.2041 4.4782 21.0944 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 184.392 1.951 94.534 &lt;2e-16 *** ## RegionSW 3.282 2.349 1.397 0.168 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 8.275 on 56 degrees of freedom ## Multiple R-squared: 0.03369, Adjusted R-squared: 0.01644 ## F-statistic: 1.953 on 1 and 56 DF, p-value: 0.1678 The Anova table for modelSL2 can be obtained by running this code: anova(modelSL2) ## Analysis of Variance Table ## ## Response: SL_mm ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Region 1 133.7 133.714 1.9525 0.1678 ## Residuals 56 3835.0 68.482 We again define a model for BB_mm. Let us call this model modelBB2. modelBB2&lt;- lm(BB_mm ~Region, data = coyoteNW_SW ) summary(modelBB2) ## ## Call: ## lm(formula = BB_mm ~ Region, data = coyoteNW_SW) ## ## Residuals: ## Min 1Q Median 3Q Max ## -7.0996 -1.2255 0.2824 1.5581 4.8819 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 56.9529 0.5604 101.63 &lt;2e-16 *** ## RegionSW -0.4198 0.6775 -0.62 0.538 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.378 on 55 degrees of freedom ## (1 observation deleted due to missingness) ## Multiple R-squared: 0.006932, Adjusted R-squared: -0.01112 ## F-statistic: 0.3839 on 1 and 55 DF, p-value: 0.5381 The Anova table for modelBB2 can be obtained by running this code: anova(modelBB2) ## Analysis of Variance Table ## ## Response: BB_mm ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Region 1 2.17 2.1702 0.3839 0.5381 ## Residuals 55 310.89 5.6526 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
